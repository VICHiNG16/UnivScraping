Yes — the **Gemini improved plan is good**. It’s well-structured, pragmatic, and close to production-ready. Nice job converging on durable data, explicit models, and a run/manifest-driven workflow.

Below I’ll be direct: first what’s excellent and should be left alone, then the few remaining improvements I’d make (with short rationale), a small prioritized checklist you can act on, and sensible next steps you can ask me to implement right away.

# What’s already excellent (keep these)

* 3-layer architecture (Directives / Execution / Data) — clear separation of concerns.
* Per-university folders + config.yaml for selectors — great for maintainability.
* Raw-first, snapshot + JSON as source-of-truth and CSV as export — correct.
* Pydantic contracts + immediate validation — huge win for correctness.
* Run manifests and run-scoped storage — makes incremental logic & audits easy.
* Error quarantine for invalid entities — good for debugging and metrics.

# Small but important changes I recommend (why + what)

1. **Use SHA256 instead of MD5 for content_hash**

   * MD5 is OK for change detection, but SHA256 is safer against collisions and cheap to compute.
   * Action: change `content_hash` to SHA256.

2. **Canonicalize & normalize source URLs before making UID**

   * Different URLs (trailing slash, `?utm=`, `http` vs `https`) must map to the same UID.
   * Action: implement a `canonicalize_url()` step (lowercase host, remove known tracking params, normalize path).

3. **Record ETag / Last-Modified and use conditional requests**

   * Use ETag/If-None-Match & If-Modified-Since to avoid re-downloading unchanged pages.
   * Action: extend `provenance` with `etag` and `last_modified`.

4. **Entity grain: one JSON per entity (faculty/program)**

   * Confirm and enforce in code (you already have this, just lock it).
   * Action: filenames = `{uid}.json` under `raw/{entity_type}/`.

5. **Content provenance: keep original and cleaned text**

   * Raw JSON should contain both: `description_html` / `description_text_raw` and `description_text_clean`.
   * Action: do cleaning in the processors stage but keep original fields unmodified.

6. **Change detection & lifecycle fields**

   * Add `last_seen_at` and `status` (active/removed/updated) later when you run incremental logic.
   * Action: manifest + simple rules (missing UID on new run -> maybe removed).

7. **Politeness settings & concurrency caps**

   * Add per-university config for `max_concurrency`, `delay_seconds`, `robots_policy` so you can tune when scaling.
   * Action: implement a `PoliteHTTPClient` wrapper honoring those settings.

8. **Testing: HTML fixtures + unit tests for parsers**

   * Add `tests/fixtures/ucv/...` and parser unit tests to fail fast when selectors break.
   * Action: CI runs tests on each PR.

9. **Verification text in plan**

   * Update the verification plan references from `.tmp/raw/` to `data/runs/{run_id}/raw/...` and include manifest checks.
   * Action: change the docs so they match the current data layout.

10. **Data store choice — start with SQLite but plan to migrate**

    * SQLite is fine for early querying; design schema so migrating to Postgres later is straightforward.
    * Action: create an `upsert` method for SQLite and a migration doc.

# Prioritized checklist (what to implement now)

1. Lock Pydantic models & provenance fields (include `etag`, `last_modified`, `content_hash` (SHA256)).
2. Implement helpers: `canonicalize_url()`, `make_uid() (sha1 or sha256 over canonical)`, `content_hash_html() (sha256)`.
3. Minimal `PoliteHTTPClient` with ETag/If-Modified-Since support and per-university config.
4. Parser unit tests + HTML fixtures for UCV discovery + one sample program page.
5. A run manifest writer that writes `data/runs/{run_id}/manifest.json` at start and finish.
6. CSV exporter that reads processed JSONs and writes `ucv_programs.csv` and `ucv_faculties.csv`.

# Small operational recommendations

* Put a clear `User-Agent` that includes contact info (e.g., `MyScraper/1.0 (+mailto:you@domain)`) — helps if sites ask you to stop.
* Start with low concurrency for each domain (1–3) and increase only after monitoring errors.
* Retain raw snapshots for at least 6–12 months; use lifecycle rules to archive older snapshots.
* Add basic observability: per-run counts, parser error rates, average response time. Use manifest for quick checks.

# Next steps I can do immediately for you (pick one; I will produce it now)

* A. Generate **final Pydantic models** (including `etag`, `last_modified`, SHA256 `content_hash`, canonical URL validator) — ready for `execution/models/`.
* B. Implement **helpers**: `canonicalize_url`, `make_uid`, `content_hash_html`, `make_run_id` (production-ready).
* C. Produce a **minimal PoliteHTTPClient** (requests + conditional requests + UA rotation + simple rate limiting).
* D. Create a **sample `config.yaml` for UCV** plus 2 parser unit-test HTML fixtures and a parser skeleton.
* E. Produce a **run manifest writer** + README snippet describing the run lifecycle and verification steps.

Tell me which letter you want (A–E) and I’ll generate the code/files for that choice right away. If you don’t pick, my single recommendation is **start with A (models + provenance)** — it makes everything else safe and testable.
