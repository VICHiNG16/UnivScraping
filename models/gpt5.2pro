Below is a “Scalability Phase” roadmap grounded in what your code is doing **today** (UCV only) and what will break/slow down when you go to **50+ universities / 200+ faculties**.

I’m going to reference concrete pressure points I see in the files:

* `run_pipeline_v4.py` hard-wires `UCVAdapter()` and runs only `BaseScraper` (no adapter factory yet). 
* `BaseScraper` is adapter-driven for HTML + PDF discovery/download, but it’s still **single-threaded/synchronous** and has no pagination/dynamic-fetch abstraction. 
* Enrichment (`DataFusionEngine`) is currently **UCV-coupled** (imports UCV PDF parser directly) and has at least one “scale blocker” bug + hard-coded year logic.
* UCV PDF parsing is already a nice “hybrid strategy” (table extraction → text/regex fallback, page provenance), which is exactly the kind of reusable primitive you’ll want cross-university. 
* Your `Program` schema and evidence fields are already designed for multi-source merging. 
* Your semantic “Iron Dome” validator is a good generic hygiene layer to keep across all sites.

---

## 1) Architecture critique: is `UniversityAdapter` robust enough for 50 universities?

### What’s good already

You’ve achieved the most important decoupling: `BaseScraper` doesn’t know DOM structure and delegates university-specific parsing and PDF link discovery to the adapter.

That’s the correct direction for 50+ sites.

### Where it will hurt at 50 universities

#### A. The adapter boundary is “HTML-only”, but the real variability is **PDF parsing**

Your interface has `parse_grades()` but **no equivalent for parsing spots PDFs**. Spots extraction is handled in `DataFusionEngine` using `PDFParser()` imported from the UCV path. That will not scale: every new university with a PDF quirk forces edits in the enrichment engine instead of “just writing a new adapter/plugin”.

**Recommendation:** make PDF parsing pluggable through the adapter boundary:

* Add either:

  * `get_spots_pdf_parser()` / `parse_spots(pdf_path)`, or
  * a more general `get_document_parsers()` returning parsers keyed by doc type (`SPOTS`, `GRADES`, maybe later `FEES`, `CALENDAR`, etc.)

This keeps the “university differences” in one place.

#### B. Pagination / multi-page flows are not representable

Right now, faculty pages are “whatever URLs you put in YAML” (`discover_faculties()` returns dicts with `urls`).

That works for UCV because you listed both `/admitere/licenta` and `/admitere/master` per faculty in YAML. 
But for many universities, program lists are:

* paginated tables (“page=1,2,3…”),
* JS-rendered,
* filtered by query params,
* behind “accordion → fetch JSON” patterns.

Your adapter can’t tell `BaseScraper` to fetch “next pages” because it only receives an `html` string and no fetch handle.

**Recommendation:** add an optional pagination hook/capability:

* `discover_additional_pages(html, url, faculty_slug) -> list[PageRequest]`
* or model your faculty as a plan (`FacultyPlan`) that can yield pages to fetch.

Keep it optional (default empty list) so most adapters stay simple.

#### C. Fetch strategy (static HTTP vs browser) isn’t a first-class concept

`BaseScraper` instantiates a `BrowserManager`, but never uses it in the shown code path.
So today you are effectively “requests-only”.

At 50 universities, you will inevitably hit:

* Cloudflare-ish “JS required” pages,
* cookie banners that block content unless accepted,
* content in script tags (JSON-LD, JS variables),
* pages that require scroll / dynamic load.

**Recommendation:** introduce `FetchMode` as adapter-driven metadata:

* `get_fetch_mode(url) -> Literal["http","browser"]` (default `"http"`)
* or `get_page_requests()` with each URL annotated with fetch mode & timeouts.

This lets you keep a simple pipeline while unlocking “browser only when needed”.

#### D. `Program` construction responsibilities are split awkwardly

UCVAdapter creates `Program` entities with a placeholder `run_id="adapter_run"` and internally recomputes `faculty_uid` hashing. Then `BaseScraper` overwrites `run_id`.

That’s a coupling smell:

* if UID rules change, you must update both adapter and base.
* run context (run_id, faculty_uid) belongs to the pipeline, not site parsing.

**Recommendation:** change adapter output to **data-only** or pass a `ScrapeContext`:

* Option 1 (clean): adapter returns `list[dict]` “program candidates” and BaseScraper builds `Program` (single source of truth for UID + run_id).
* Option 2: keep returning `Program`, but pass `run_id` + `faculty_uid` into `extract_programs_from_html(...)`.

#### E. Enrichment engine is not adapter-driven (and has scale blockers)

`DataFusionEngine` currently:

* imports `PDFParser` from `execution.scrapers.ucv.pdf_parser` (UCV-specific)
* has a hard-coded year in `_identify_spots_pdf`: `PDFTruthRanker(admission_year=2026)` instead of using `self.admission_year` 
* contains a leftover reference to `pdf_rows` that is undefined (will crash when that path is hit).

Before scaling, you want:

* a generic enrichment runner that uses **adapter-provided parsers**, not UCV imports
* consistent ranker configuration (one place, not duplicated)

This is the biggest architectural bottleneck to “50 adapters”.

---

## 2) Factory pattern: managing 50+ adapter class files dynamically

### Keep per-university folders (your current pattern is good)

Your current structure (`execution/scrapers/ucv/adapter.py` + `config.yaml`) is exactly what you want at 50 universities: it “namespaces” quirks and makes ownership obvious.

So I’d keep:

```
execution/
  scrapers/
    ucv/
      adapter.py
      config.yaml
      pdf_parser.py          # optional, if needed
      tests/                 # snapshots + unit tests
    ub/
      adapter.py
      config.yaml
    upb/
      ...
    registry.py
```

### Add a registry + factory (simple internal “plugin system”)

Right now the runner imports `UCVAdapter` directly. 
At 50 universities you want:

* CLI: `python run_pipeline.py --uni ucv`
* or batch: `python run_all.py --unis ucv,ub,upb`

**Minimal approach (recommended): decorator registry**

`execution/scrapers/registry.py`:

```py
# registry.py
from typing import Dict, Type
from execution.scrapers.adapter_interface import UniversityAdapter

REGISTRY: Dict[str, Type[UniversityAdapter]] = {}

def register(slug: str):
    def deco(cls):
        REGISTRY[slug] = cls
        return cls
    return deco

def create_adapter(slug: str) -> UniversityAdapter:
    try:
        return REGISTRY[slug]()
    except KeyError:
        raise ValueError(f"Unknown university slug: {slug}. Known: {sorted(REGISTRY)}")
```

Each adapter:

```py
from execution.scrapers.registry import register

@register("ucv")
class UCVAdapter(UniversityAdapter):
    ...
```

Runner:

```py
from execution.scrapers.registry import create_adapter
adapter = create_adapter(args.uni)
BaseScraper(run_id=..., adapter=adapter).run()
```

This avoids auto-import weirdness and stays very explicit.

**Alternative (auto-discovery):** scan subpackages under `execution.scrapers` and import `adapter.py` modules dynamically. This reduces boilerplate but increases “import side effects” risk (importing 50 modules every run). I’d only do it if you *really* want “drop-in new folder = auto available”.

**When to use “real plugins” (entry_points):**
Only if you expect 3rd parties to ship adapters separately (pip-installable). For your internal project, a registry is enough.

---

## 3) Configuration vs Code: should selectors go into YAML?

You already started the right direction: **faculty definitions and concurrency settings** exist in `config.yaml`.
But most extraction logic is still hard-coded in `UCVAdapter` (container selection, regexes, blacklist patterns, PDF-only faculties, keyword lists). 

### Recommendation: a hybrid rule

* Put **stable, declarative things** in YAML.
* Keep **algorithmic logic / fallbacks** in Python.

If you go “YAML-only”, you’ll inevitably invent a DSL for:

* state (“current_domain” tracking),
* heuristics,
* multi-step extraction,
* conditional rules,
* post-processing normalization.

That DSL becomes harder to test than Python, and you’ll end up reimplementing Python poorly.

### What belongs in YAML (high ROI)

Move these from code to config (because they vary per site and don’t require algorithms):

1. **Faculty list, URLs, and flags**

* `faculties[].pdf_only: true`
* `faculties[].levels: ["Licenta","Master"]` or similar

UCV currently hard-codes `PDF_ONLY_FACULTIES = ["agronomie"]`. That should be per-faculty config. 

2. **HTML container selectors (fallback list)**
   UCV uses:

* `div#continut_standard` or `div#main_content` else whole doc. 
  These are perfect to externalize as a list.

3. **PDF candidate extraction rules**
   Most universities: `a[href$=".pdf"]` is fine. Some: PDF links are hidden in JS or require regex.

Keep a default “find all .pdf links”, but allow config to override:

* allowed domains
* exclude patterns
* include keywords/weights

4. **Grade PDF keyword scoring**
   UCV uses `KEYWORDS` and `NEGATIVE_KEYWORDS` in code. That should be config so you can tune quickly when a site changes wording. 

5. **Rate limiting / domain groups**
   You already have `async_settings.domain_groups` in YAML, but the pipeline doesn’t use it yet.
   That’s exactly the kind of thing that should live in config, not code.

### What should stay in Python (to avoid YAML DSL hell)

Keep in Python:

* multi-strategy extraction pipelines (“try table parse, fallback regex”), like your PDF parser already does 
* normalization rules (diacritics, abbreviations) like in `RomanianProgramMatcher` 
* any logic that depends on parsing structure and then taking actions (pagination discovery, JS-render handling)

### Critical add: validate YAML with Pydantic

Your adapters currently `yaml.safe_load` and silently fall back to `{faculties: []}` on missing file. 
That’s nice for resilience, but at 50 universities it becomes a debugging nightmare (“why did it scrape 0 faculties?”).

Create `UniversityConfig` and `FacultyConfig` Pydantic models, then:

* fail fast in dev (raise)
* in prod, quarantine config errors with a clear message and skip that university

---

## 4) Concurrency & resilience: run 50 scrapers without Celery/Redis

You can keep this simple. You don’t need Celery unless you want distributed workers, durable queues, scheduling, retries across machines, etc.

### Option A (lowest refactor): process-level parallelism (recommended first step)

Keep your current synchronous `BaseScraper` flow. 
Create a new “orchestrator” that runs multiple universities in parallel using `ProcessPoolExecutor` (or even `ThreadPoolExecutor` if mostly network I/O).

* Each worker:

  * creates adapter via factory
  * runs `BaseScraper(run_id=..., adapter=...)`
  * then runs enrichment (once you refactor it to be adapter-driven)

**Why process-based is attractive here:**

* isolates memory leaks from browser automation
* isolates “weird PDF parsing crashes”
* you can hard-cap max parallel universities (e.g., 4–8) without a distributed system

### Option B (best throughput, moderate refactor): AsyncIO for HTTP + bounded pools

Your `config.yaml` already hints you want this (domain groups, timeouts, circuit breaker). 

A simple AsyncIO design (no Celery):

* Global `AsyncClient` (httpx/aiohttp)
* Per-domain-group `asyncio.Semaphore(max_concurrent)`
* Token-bucket rate limiter per domain (or simple “sleep between requests per domain”)
* Circuit breaker per domain group (you already modeled thresholds in config) 
* PDF parsing pushed into a `ProcessPoolExecutor` (pdfplumber can be CPU-heavy)

This gives you “50 universities concurrently” in one process *without* creating 50 browsers and without external infra.

### Browser instances (shared resources) without complexity

Make browser usage explicit:

* Only use browser mode for universities/URLs that need it (`FetchMode="browser"`).
* Use a **single browser per process** and a pool of contexts/pages:

  * `max_pages = N` (e.g., 2–4)
  * protect with semaphore
* Close contexts after each page to avoid memory blowup.

Right now you instantiate `BrowserManager` but don’t use it. As soon as you add `FetchMode`, you can start using it only when required.

### Rate limiting without a queue

You can implement a “polite scheduler” in ~100 lines:

* key = domain group (from YAML)
* each group has:

  * semaphore concurrency
  * minimum delay between requests (token bucket)
  * error counter + reset timer (circuit breaker)
* `BaseScraper` should request pages through this scheduler instead of calling `http_client.get()` directly

Your YAML already has the right shape for this. 

---

## Suggested Scalability Roadmap (practical, staged)

### Phase 0: Fix scale blockers (do before adding 10+ universities)

1. **Decouple enrichment from UCV**

* `DataFusionEngine` must not import `execution.scrapers.ucv.pdf_parser.PDFParser`. It should ask the adapter for a parser.

2. **Remove hard-coded year `2026`**

* `_identify_spots_pdf` should use `self.admission_year` or adapter config. 

3. **Fix the undefined `pdf_rows` reference**

* There’s a leftover `valid_rows = [r for r in pdf_rows ...]` after `pdf_rows_list` is built, which will crash.

4. **Make run IDs collision-safe**

* `run_pipeline_v4.py` uses timestamp seconds; concurrent starts can collide. Use uuid or include slug. 

### Phase 1: Adapter factory + consistent packaging

* Implement registry/factory
* Update runner to take `--uni` and instantiate adapter dynamically
* Keep `execution/scrapers/{slug}/adapter.py` and `config.yaml` convention

This unlocks “50 adapters” without touching the runner each time.

### Phase 2: Make adapters “capability-based” (pagination, fetch mode, parsers)

Extend `UniversityAdapter` with optional capabilities (defaults provided):

* `get_fetch_mode(url)` or per-URL metadata
* `discover_additional_pages(...)` (pagination)
* `parse_spots(...)` or `get_spots_parser()`

Keep the required interface small, and let advanced universities implement the extra hooks. 

### Phase 3: Config normalization (hybrid config + code)

* Define `UniversityConfig` Pydantic model
* Move selector lists, keyword lists, and faculty flags into YAML
* Keep fallback/heuristics in Python

This reduces adapter code volume while preserving flexibility.

### Phase 4: Concurrency (simple → powerful)

* Start with `ProcessPoolExecutor` to run multiple universities concurrently (fastest to implement).
* Then (if needed) refactor the fetch layer to AsyncIO using your existing config model for domain groups, circuit breakers, and PDF concurrency.

---

## Direct answers to your 4 specific questions

### 1) Factory pattern: folder-per-university or plugin system?

**Folder-per-university + registry/factory** is the sweet spot:

* keeps codebase navigable
* keeps config close to code
* avoids external plugin complexity until you need it

Implement a registry decorator + `create_adapter(slug)`; update `run_pipeline_v4.py` style runner to select by slug.

### 2) Configuration vs code: selectors into YAML?

**Yes, but hybrid.**

* Move “selectors + keyword lists + faculty flags + rate limits” into YAML.
* Keep “multi-strategy parsing + heuristics + normalization” in Python.

Also add Pydantic validation for YAML so broken configs don’t silently become “0 faculties scraped”.

### 3) Resilience without Celery/Redis?

Use **bounded concurrency + domain-group rate limiting + circuit breaker**:

* simplest: run universities in parallel processes (4–8 workers), keep BaseScraper mostly unchanged
* better: AsyncIO with semaphores per domain group (you already modeled this in config)

### 4) Adapter interface review: missing Pagination / Authentication?

**Pagination is the big missing one.** Without it, you must hardcode all pages in YAML forever.
Authentication is “maybe”; most universities won’t require it, so make it optional:

* optional `get_http_headers()/get_cookies()`
* optional `login()` or “session bootstrap” hook

Also missing: adapter-provided spots PDF parsing (right now enrichment is UCV-coupled).

---

If you want one guiding principle for the Scalability Phase:

**Make the adapter the single “university boundary” for HTML discovery + PDF discovery + document parsing, and make the runner/orchestrator responsible for fetching, rate limiting, concurrency, and run context.**

That’s how you get to 50+ universities without turning the core pipeline into a pile of special cases.
